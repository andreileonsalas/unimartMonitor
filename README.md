# Unimart Price Tracker üè™üìä

A lightweight price tracking application for unimart.com products, similar to CamelCamelCamel. This tool automatically monitors product prices daily and displays historical trends in your browser - no backend or authentication required!

## Features

- üìà **Daily Price Tracking**: Automatically scrapes prices from unimart.com using GitHub Actions
- üíæ **SQLite Storage**: All data stored in a single SQLite file - no external database needed
- üåê **Browser-Based Viewer**: View price history directly in your browser using client-side SQLite
- ü§ñ **Automated**: Runs daily via GitHub Actions - no server required
- üîç **Search & Filter**: Easily search through tracked products
- üìâ **Price History**: See how prices change over time for each product
- üé® **Beautiful UI**: Clean, modern interface with price change indicators

## How It Works

1. **GitHub Actions** runs daily to:
   - Fetch the sitemap from https://www.unimart.com/sitemap.xml
   - Extract product URLs
   - Scrape current prices
   - Store data in SQLite database (`prices.db`)
   - Commit changes back to the repository

2. **Browser Viewer** (`index.html`):
   - Loads the SQLite database directly in your browser using sql.js
   - Displays all tracked products with current prices
   - Shows price trends and history
   - Fully client-side - no backend needed!

## Setup

### Prerequisites

- Node.js 20 or higher (requerido para el scraper)
- npm

### Installation

1. Clone this repository:
```bash
git clone https://github.com/andreileonsalas/unimartMonitor.git
cd unimartMonitor
```

2. Install dependencies:
```bash
npm install
```

### Running the Scraper

To run the scraper manually:

```bash
npm run scrape
```

This will:
- Fetch the sitemap from unimart.com
- Extract product URLs
- Scrape prices from up to 50 products
- Save data to `prices.db`

## üåê C√≥mo Ver la Aplicaci√≥n (Sin GitHub Pages)

### ‚ú® Opci√≥n 1: Ver Directo desde GitHub (M√ÅS F√ÅCIL - SIN DESCARGAR NADA)

Usa estos servicios que renderizan HTML directamente desde GitHub:

#### **üöÄ Opci√≥n A: Raw.githack.com (RECOMENDADO)**
```
https://raw.githack.com/andreileonsalas/unimartMonitor/main/index.html
```
- ‚úÖ Muy r√°pido
- ‚úÖ Con CDN
- ‚úÖ Actualizaci√≥n autom√°tica

#### **üöÄ Opci√≥n B: HTMLPreview.github.io**
```
https://htmlpreview.github.io/?https://github.com/andreileonsalas/unimartMonitor/blob/main/index.html
```
- ‚úÖ Servicio oficial de GitHub
- ‚úÖ Sin configuraci√≥n

**¬øC√≥mo funciona?** Estos servicios descargan tu HTML y la base de datos `prices.db` directamente desde GitHub y los sirven con los headers correctos para que funcione en el navegador. 

**¬øEs seguro?** S√≠, porque tanto el HTML como el archivo `prices.db` ya son p√∫blicos en tu repositorio de GitHub. Cualquiera puede descargarlos.

**Actualizaci√≥n autom√°tica**: Cada vez que el GitHub Action actualice `prices.db` y haga commit, estos links mostrar√°n los datos m√°s recientes autom√°ticamente (puede tardar 1-2 minutos en actualizar el cach√©).

### ‚ú® Opci√≥n 2: Con Python (RECOMENDADO para uso local)

Si tienes Python instalado (viene pre-instalado en Mac/Linux):

```bash
# Entra a la carpeta del proyecto
cd unimartMonitor

# Inicia el servidor
python -m http.server 8000

# O en Python 2:
python -m SimpleHTTPServer 8000
```

Luego abre tu navegador en: **http://localhost:8000**

### ‚ú® Opci√≥n 3: Con Node.js

Si prefieres usar Node.js:

```bash
# Opci√≥n A: Con http-server (m√°s r√°pido)
npx http-server -p 8000

# Opci√≥n B: Con live-server (se recarga autom√°ticamente)
npx live-server --port=8000
```

Luego abre tu navegador en: **http://localhost:8000**

### ‚ú® Opci√≥n 4: Con Visual Studio Code (S√öPER F√ÅCIL)

1. **Instala la extensi√≥n "Live Server"**:
   - Abre VS Code
   - Ve a Extensions (Ctrl+Shift+X o Cmd+Shift+X)
   - Busca "Live Server" de Ritwick Dey
   - Haz clic en "Install"

2. **Abre el proyecto**:
   - Abre la carpeta `unimartMonitor` en VS Code

3. **Inicia el servidor**:
   - Haz clic derecho en `index.html`
   - Selecciona "Open with Live Server"
   - ¬°Listo! Se abrir√° autom√°ticamente en tu navegador

### ‚ú® Opci√≥n 5: En cPanel / Hosting Web

Si tienes un hosting con cPanel:

1. **Sube estos archivos a `public_html`**:
   ```
   index.html
   viewer.js
   prices.db
   ```

2. **C√≥mo subir**:
   - Entra a cPanel ‚Üí File Manager
   - Navega a `public_html`
   - Haz clic en "Upload"
   - Arrastra los 3 archivos mencionados
   - ¬°Listo!

3. **Accede a tu sitio**:
   - `http://tudominio.com/index.html`
   - O simplemente `http://tudominio.com/` si renombras `index.html`

4. **Actualizar precios**:
   - Cada vez que el GitHub Action actualice `prices.db`
   - Descarga el nuevo `prices.db` del repositorio
   - S√∫belo a tu cPanel (reemplaza el anterior)

### ‚ú® Opci√≥n 6: Con PHP Built-in Server

Si tienes PHP instalado:

```bash
php -S localhost:8000
```

Luego abre: **http://localhost:8000**

## üì∏ Preview de la Aplicaci√≥n

![Unimart Price Tracker](https://github.com/user-attachments/assets/356c3b3a-a560-4088-9c20-be243f8eff19)

La aplicaci√≥n muestra:
- üìä Estad√≠sticas totales (productos, registros, √∫ltima actualizaci√≥n)
- üîç Buscador en tiempo real
- üí∞ Precios actuales con moneda
- üìà Historial de cambios de precio
- üé® Interfaz moderna y responsiva

## Automated Daily Tracking

The GitHub Actions workflow (`.github/workflows/scrape.yml`) runs automatically every day at 2 AM UTC. It will:

1. Install dependencies
2. Run the scraper
3. Commit the updated database
4. Push changes to the repository

You can also trigger it manually:
- Go to "Actions" tab in GitHub
- Select "Daily Price Scraper"
- Click "Run workflow"

## GitHub Pages Deployment

### Paso a Paso para Habilitar GitHub Pages:

1. **Ve a tu repositorio en GitHub**
   - Navega a `https://github.com/andreileonsalas/unimartMonitor`

2. **Abre la configuraci√≥n**
   - Haz clic en la pesta√±a "Settings" (‚öôÔ∏è)

3. **Ve a Pages**
   - En el men√∫ lateral izquierdo, busca y haz clic en "Pages"

4. **Configura la fuente**
   - En "Build and deployment" ‚Üí "Source", selecciona: **Deploy from a branch**
   - En "Branch", selecciona: **main** (o tu rama principal)
   - Folder: **/ (root)**
   - Haz clic en **Save**

5. **Espera el deployment**
   - GitHub Pages tardar√° 1-2 minutos en construir el sitio
   - Ver√°s un mensaje verde cuando est√© listo

6. **Accede a tu tracker**
   - URL: `https://andreileonsalas.github.io/unimartMonitor/`
   - ¬°Listo! Tu price tracker est√° en vivo üéâ

### Soluci√≥n de Problemas

- **P√°gina no carga**: Espera 2-3 minutos despu√©s de activar Pages
- **404 Error**: Verifica que la rama seleccionada sea la correcta
- **Base de datos no carga**: Aseg√∫rate que `prices.db` est√© commiteado en el repositorio

## Database Schema

### Products Table
- `id`: Primary key
- `url`: Product URL (unique identifier)
- `sku`: Product SKU from Unimart (indexed for fast search)
- `title`: Product title
- `last_scraped`: Last scrape timestamp

**Note:** Both URL and SKU are stored to maintain dual reference. If Unimart changes the URL or SKU, historical data is preserved.

### Prices Table
- `id`: Primary key
- `product_id`: Foreign key to products
- `price`: Product price
- `currency`: Currency code (CRC for Costa Rican Col√≥n, USD, EUR, etc.)
- `scraped_at`: Timestamp of scrape

## Configuration

### Scraper Settings

Edit `scraper.js` to customize:

- **Product limit**: Change `const MAX_PRODUCTS_PER_RUN = 50;` to scrape more/fewer products per run
- **Delay**: Adjust `const REQUEST_DELAY_MS = 1000;` to change delay between requests (in milliseconds)
- **URL filters**: The scraper automatically filters for `/products/` URLs from Unimart

### Workflow Schedule

Edit `.github/workflows/scrape.yml` to change the schedule:

```yaml
schedule:
  - cron: '0 2 * * *'  # Change this line
```

## Technologies Used

- **Node.js**: Scraper runtime
- **Axios**: HTTP requests
- **Cheerio**: HTML parsing
- **xml2js**: Sitemap parsing
- **better-sqlite3**: SQLite database for Node.js
- **sql.js**: SQLite in the browser (WebAssembly)
- **GitHub Actions**: Automation
- **Vanilla JavaScript**: Browser viewer (no frameworks)

## Project Structure

```
unimartMonitor/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ scrape.yml          # GitHub Actions workflow
‚îú‚îÄ‚îÄ scraper.js                  # Main scraper script
‚îú‚îÄ‚îÄ index.html                  # Browser viewer UI
‚îú‚îÄ‚îÄ viewer.js                   # Browser viewer logic
‚îú‚îÄ‚îÄ prices.db                   # SQLite database (generated)
‚îú‚îÄ‚îÄ package.json                # Node.js dependencies
‚îî‚îÄ‚îÄ README.md                   # This file
```

## üîß Si Unimart Cambia su Estructura

### Edge Cases Verificados

‚úÖ **Sitemap Index**: El sitemap principal tiene 1,245 sitemaps referenciados
‚úÖ **Product Sitemaps**: Los primeros 1,228 contienen productos
‚úÖ **Otros Sitemaps**: Los √∫ltimos son collections/articles/blogs (NO productos)
‚úÖ **Estructura Uniforme**: Todos los product sitemaps tienen el mismo formato
‚úÖ **Uso del Primero**: Es SEGURO usar solo el primer sitemap - no hay diferencias

### D√≥nde Hacer Cambios

#### 1. Si Cambia la URL del Sitemap

**Archivo**: `scraper.js` (l√≠nea 10)

```javascript
// üîß CAMBIAR AQU√ç si la URL del sitemap cambia
const SITEMAP_URL = 'https://www.unimart.com/sitemap.xml';
```

#### 2. Si Cambia la Estructura del Sitemap Index

**Archivo**: `scraper.js` (l√≠neas 58-90)

```javascript
// üîß CAMBIAR AQU√ç si la estructura del sitemap index cambia
if (result.sitemapindex && result.sitemapindex.sitemap) {
  // Ajusta c√≥mo se extraen las referencias a otros sitemaps
  const firstSitemapUrl = result.sitemapindex.sitemap[0].loc[0];
  // ...
}
```

#### 3. Si Cambia el Selector de Precio en la P√°gina

**Archivo**: `scraper.js` (l√≠nea 165)

```javascript
// üîß CAMBIAR AQU√ç si el HTML de la p√°gina de producto cambia
// Actualmente el precio est√° en la clase .money
const priceText = $('.money').first().text().trim() ||
                $('.price').first().text() ||
                // Agrega nuevos selectores aqu√≠
```

**C√≥mo verificar el nuevo selector:**
1. Abre una p√°gina de producto en unimart.com
2. Click derecho ‚Üí "Inspeccionar elemento" en el precio
3. Encuentra la clase o ID del elemento
4. Actualiza el selector en el c√≥digo

#### 4. Si Cambia el Formato del SKU

**Archivo**: `scraper.js` (l√≠nea 156)

```javascript
// üîß CAMBIAR AQU√ç si el formato del SKU en el JSON cambia
const skuMatch = content.match(/"sku"\s*:\s*"([^"]+)"/);
```

#### 5. Si Cambia el S√≠mbolo de Moneda

**Archivo**: `scraper.js` (l√≠neas 177-185)

```javascript
// üîß CAMBIAR AQU√ç si cambian de s√≠mbolo de moneda
if (priceText.includes('‚Ç°')) {
  currency = 'CRC';
} // Agrega nuevos s√≠mbolos aqu√≠
```

### Herramientas para Debugging

```bash
# Ver la estructura del sitemap actual
curl https://www.unimart.com/sitemap.xml | head -100

# Ver el HTML de una p√°gina de producto
curl https://www.unimart.com/products/[nombre-producto] | grep -i "price\|money"

# Probar el scraper manualmente
npm run scrape
```

## Troubleshooting

### Database not loading in browser
- Make sure you have run the scraper at least once
- Verify `prices.db` exists in the repository
- Check browser console for errors

### Scraper not finding products
- The product URL patterns may need adjustment
- Check if unimart.com's sitemap structure has changed
- Modify the URL filter logic in `scraper.js`

### Price extraction issues
- Product page HTML selectors may need updating
- Check the actual HTML structure of unimart.com product pages
- Adjust the selectors in the `scrapeProduct()` function

## License

MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
