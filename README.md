# Unimart Price Tracker üè™üìä

A lightweight price tracking application for unimart.com products, similar to CamelCamelCamel. This tool automatically monitors product prices daily and displays historical trends in your browser - no backend or authentication required!

## üöÄ C√≥mo Ver la Aplicaci√≥n

### ‚ö†Ô∏è IMPORTANTE: Haz el Repositorio P√∫blico Primero

Para usar las opciones online (GitHub Pages, Netlify), necesitas hacer el repositorio p√∫blico:

1. Ve a tu repositorio en GitHub: `https://github.com/andreileonsalas/unimartMonitor`
2. Click en **Settings** (‚öôÔ∏è)
3. Baja hasta el final de la p√°gina
4. En la secci√≥n "Danger Zone", click en **Change visibility**
5. Selecciona **Make public**
6. Confirma escribiendo el nombre del repositorio

**¬øPor qu√© hacerlo p√∫blico?**
- GitHub Pages gratis solo funciona con repos p√∫blicos
- Los datos ya son precios p√∫blicos de Unimart, no hay informaci√≥n sensible
- Te permite compartir la aplicaci√≥n con otros sin necesidad de dar acceso al repo

---

### üåê Opci√≥n 1: GitHub Pages (RECOMENDADO - Sin instalar nada)

**‚ö†Ô∏è Primero: Haz merge del Pull Request a la rama `main`**

1. Ve a: `https://github.com/andreileonsalas/unimartMonitor/pulls`
2. Busca el Pull Request "Fix scraper reference error" (o similar)
3. Click en **"Merge pull request"**
4. Click en **"Confirm merge"**
5. Espera 30 segundos a que se complete el merge

**Luego, activa GitHub Pages:**

1. Ve a tu repositorio: `https://github.com/andreileonsalas/unimartMonitor`
2. Click en **Settings** (‚öôÔ∏è)
3. En el men√∫ izquierdo, click en **Pages**
4. En "Build and deployment":
   - **Source**: Deploy from a branch
   - **Branch**: main
   - **Folder**: / (root)
5. Click en **Save**
6. Espera 1-2 minutos

**Tu aplicaci√≥n estar√° disponible en:**
```
https://andreileonsalas.github.io/unimartMonitor/
```

‚úÖ **Ventajas:**
- Acceso desde cualquier dispositivo con internet
- Se actualiza autom√°ticamente cuando el GitHub Action actualiza los datos
- No necesitas instalar nada en tu computadora
- Es 100% GRATIS (no requiere pago)

### üåç Opci√≥n 2: Usando CDN (Funciona INMEDIATAMENTE despu√©s del merge)

**‚ö†Ô∏è Nota:** Estas URLs funcionar√°n autom√°ticamente despu√©s de que hagas merge del PR a `main` (ver Opci√≥n 1).

Estas URLs funcionan sin necesidad de activar nada (solo copia y pega en tu navegador):

**Opci√≥n A - jsDelivr CDN (RECOMENDADO):**
```
https://cdn.jsdelivr.net/gh/andreileonsalas/unimartMonitor@main/index.html
```

**Opci√≥n B - RawCDN GitHack:**
```
https://rawcdn.githack.com/andreileonsalas/unimartMonitor/main/index.html
```

‚úÖ **Ventajas:**
- Funciona INMEDIATAMENTE (no necesitas configurar GitHub Pages)
- Solo copia y pega la URL en tu navegador
- Se actualiza autom√°ticamente con cada commit a `main`
- Gratis y sin configuraci√≥n
- S√∫per r√°pido (usa CDN global)

‚ö†Ô∏è **Nota:** Estos servicios usan cach√©, as√≠ que los datos pueden tardar unos minutos en actualizarse despu√©s de que el GitHub Action corra.

### üåç Opci√≥n 3: Netlify Drop (Arrastra y suelta - MUY F√ÅCIL)

**‚úÖ Funciona con repo p√∫blico o privado**

1. Ve a [https://app.netlify.com/drop](https://app.netlify.com/drop)
2. Descarga estos 3 archivos de tu repositorio:
   - `index.html`
   - `viewer.js`
   - `prices.db`
3. Arrastra los 3 archivos a la zona de Netlify Drop
4. ¬°Listo! Te dar√° una URL como: `https://random-name-123.netlify.app`

‚úÖ **Ventajas:**
- Sin cuenta necesaria (modo an√≥nimo)
- S√∫per r√°pido (arrastra y suelta)
- Gratis
- Funciona aunque el repo sea privado

‚ö†Ô∏è **Nota:** Para actualizar los datos, necesitas volver a subir el archivo `prices.db` actualizado.

### üì± Opci√≥n 4: Directamente desde tu Navegador (Solo para probar)

1. **Descarga solo estos 3 archivos del repositorio:**
   - `index.html`
   - `viewer.js`
   - `prices.db`

2. **Abre `index.html` con tu navegador** (doble clic en el archivo)

‚ö†Ô∏è **Nota**: Algunos navegadores pueden bloquear la carga del archivo SQLite por seguridad. Si ves un error, usa una de las opciones con servidor.

### üíª Opci√≥n 5: Con un Servidor Local (Para desarrollo)

Descarga el repositorio completo y usa cualquiera de estos m√©todos:

**A) Con Python (lo m√°s simple - viene instalado en Mac/Linux):**
```bash
cd unimartMonitor
python -m http.server 8000
```
Luego abre en tu navegador: **http://localhost:8000**

**B) Con Visual Studio Code (s√∫per f√°cil):**
1. Abre la carpeta `unimartMonitor` en VS Code
2. Instala la extensi√≥n "Live Server" (Ritwick Dey)
3. Clic derecho en `index.html` ‚Üí "Open with Live Server"

**C) Con Node.js:**
```bash
npx http-server -p 8000
```
Luego abre: **http://localhost:8000**

### üåê Opci√≥n 6: En tu Servidor Web / Hosting

Si tienes un hosting con cPanel o FTP:

1. Sube estos 3 archivos a tu carpeta web (`public_html`, `www`, etc.):
   - `index.html`
   - `viewer.js`  
   - `prices.db`

2. Accede desde tu navegador: `http://tudominio.com/index.html`

3. Para actualizar precios: descarga el nuevo `prices.db` del repo y s√∫belo (cada vez que el GitHub Action lo actualice)

## üì∏ Preview

![Unimart Price Tracker](https://github.com/user-attachments/assets/356c3b3a-a560-4088-9c20-be243f8eff19)

La aplicaci√≥n muestra:
- üìä Estad√≠sticas totales (productos, registros, √∫ltima actualizaci√≥n)
- üîç Buscador en tiempo real
- üí∞ Precios actuales con moneda (CRC - Colones)
- üìà Historial de cambios de precio al hacer clic en cada producto
- üé® Interfaz moderna y responsiva

## Features

- üìà **Daily Price Tracking**: Automatically scrapes prices from unimart.com using GitHub Actions
- üíæ **SQLite Storage**: All data stored in a single SQLite file - no external database needed
- üåê **Browser-Based Viewer**: View price history directly in your browser using client-side SQLite
- ü§ñ **Automated**: Runs daily via GitHub Actions - no server required
- üîç **Search & Filter**: Easily search through tracked products
- üìâ **Price History**: See how prices change over time for each product
- üé® **Beautiful UI**: Clean, modern interface with price change indicators

## How It Works

1. **GitHub Actions** runs daily to:
   - Fetch the sitemap from https://www.unimart.com/sitemap.xml
   - Extract product URLs
   - Scrape current prices
   - Store data in SQLite database (`prices.db`)
   - Commit changes back to the repository

2. **Browser Viewer** (`index.html`):
   - Loads the SQLite database directly in your browser using sql.js
   - Displays all tracked products with current prices
   - Shows price trends and history
   - Fully client-side - no backend needed!

## Setup

### Prerequisites

- Node.js 20 or higher (requerido para el scraper)
- npm

### Installation

1. Clone this repository:
```bash
git clone https://github.com/andreileonsalas/unimartMonitor.git
cd unimartMonitor
```

2. Install dependencies:
```bash
npm install
```

### Running the Scraper

To run the scraper manually:

```bash
npm run scrape
```

This will:
- Fetch the sitemap from unimart.com
- Extract product URLs
- Scrape prices from up to 50 products
- Save data to `prices.db`

## ü§ñ Automated Daily Tracking

The GitHub Actions workflow (`.github/workflows/scrape.yml`) runs automatically every day at 2 AM UTC. It will:

1. Install dependencies
2. Run the scraper
3. Commit the updated database
4. Push changes to the repository

**Trigger manual:** Puedes ejecutarlo manualmente desde GitHub:
- Ve a "Actions" tab en GitHub
- Selecciona "Daily Price Scraper"
- Clic en "Run workflow"

---

## üîß Para Desarrolladores

### Prerequisites

- Node.js 20 or higher (requerido para el scraper)
- npm

### Installation

1. Clone this repository:
```bash
git clone https://github.com/andreileonsalas/unimartMonitor.git
cd unimartMonitor
```

2. Install dependencies:
```bash
npm install
```

### Running the Scraper Locally

To run the scraper manually:

```bash
npm run scrape
```

This will:
- Fetch the sitemap from unimart.com
- Extract product URLs
- Scrape prices from up to 50 products
- Save data to `prices.db`

The GitHub Actions workflow (`.github/workflows/scrape.yml`) runs automatically every day at 2 AM UTC. It will:

1. Install dependencies
2. Run the scraper
3. Commit the updated database
4. Push changes to the repository

You can also trigger it manually:
- Go to "Actions" tab in GitHub
- Select "Daily Price Scraper"
- Click "Run workflow"

## Database Schema

### Products Table
- `id`: Primary key
- `url`: Product URL (unique identifier)
- `sku`: Product SKU from Unimart (indexed for fast search)
- `title`: Product title
- `last_scraped`: Last scrape timestamp

**Note:** Both URL and SKU are stored to maintain dual reference. If Unimart changes the URL or SKU, historical data is preserved.

### Prices Table
- `id`: Primary key
- `product_id`: Foreign key to products
- `price`: Product price
- `currency`: Currency code (CRC for Costa Rican Col√≥n, USD, EUR, etc.)
- `scraped_at`: Timestamp of scrape

## Configuration

### Scraper Settings

Edit `scraper.js` to customize:

- **Product limit**: Change `const MAX_PRODUCTS_PER_RUN = 50;` to scrape more/fewer products per run
- **Delay**: Adjust `const REQUEST_DELAY_MS = 1000;` to change delay between requests (in milliseconds)
- **URL filters**: The scraper automatically filters for `/products/` URLs from Unimart

### Workflow Schedule

Edit `.github/workflows/scrape.yml` to change the schedule:

```yaml
schedule:
  - cron: '0 2 * * *'  # Change this line
```

## Technologies Used

- **Node.js**: Scraper runtime
- **Axios**: HTTP requests
- **Cheerio**: HTML parsing
- **xml2js**: Sitemap parsing
- **better-sqlite3**: SQLite database for Node.js
- **sql.js**: SQLite in the browser (WebAssembly)
- **GitHub Actions**: Automation
- **Vanilla JavaScript**: Browser viewer (no frameworks)

## Project Structure

```
unimartMonitor/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ scrape.yml          # GitHub Actions workflow
‚îú‚îÄ‚îÄ scraper.js                  # Main scraper script
‚îú‚îÄ‚îÄ index.html                  # Browser viewer UI
‚îú‚îÄ‚îÄ viewer.js                   # Browser viewer logic
‚îú‚îÄ‚îÄ prices.db                   # SQLite database (generated)
‚îú‚îÄ‚îÄ package.json                # Node.js dependencies
‚îî‚îÄ‚îÄ README.md                   # This file
```

## üîß Si Unimart Cambia su Estructura

### Edge Cases Verificados

‚úÖ **Sitemap Index**: El sitemap principal tiene 1,245 sitemaps referenciados
‚úÖ **Product Sitemaps**: Los primeros 1,228 contienen productos
‚úÖ **Otros Sitemaps**: Los √∫ltimos son collections/articles/blogs (NO productos)
‚úÖ **Estructura Uniforme**: Todos los product sitemaps tienen el mismo formato
‚úÖ **Uso del Primero**: Es SEGURO usar solo el primer sitemap - no hay diferencias

### D√≥nde Hacer Cambios

#### 1. Si Cambia la URL del Sitemap

**Archivo**: `scraper.js` (l√≠nea 10)

```javascript
// üîß CAMBIAR AQU√ç si la URL del sitemap cambia
const SITEMAP_URL = 'https://www.unimart.com/sitemap.xml';
```

#### 2. Si Cambia la Estructura del Sitemap Index

**Archivo**: `scraper.js` (l√≠neas 58-90)

```javascript
// üîß CAMBIAR AQU√ç si la estructura del sitemap index cambia
if (result.sitemapindex && result.sitemapindex.sitemap) {
  // Ajusta c√≥mo se extraen las referencias a otros sitemaps
  const firstSitemapUrl = result.sitemapindex.sitemap[0].loc[0];
  // ...
}
```

#### 3. Si Cambia el Selector de Precio en la P√°gina

**Archivo**: `scraper.js` (l√≠nea 165)

```javascript
// üîß CAMBIAR AQU√ç si el HTML de la p√°gina de producto cambia
// Actualmente el precio est√° en la clase .money
const priceText = $('.money').first().text().trim() ||
                $('.price').first().text() ||
                // Agrega nuevos selectores aqu√≠
```

**C√≥mo verificar el nuevo selector:**
1. Abre una p√°gina de producto en unimart.com
2. Click derecho ‚Üí "Inspeccionar elemento" en el precio
3. Encuentra la clase o ID del elemento
4. Actualiza el selector en el c√≥digo

#### 4. Si Cambia el Formato del SKU

**Archivo**: `scraper.js` (l√≠nea 156)

```javascript
// üîß CAMBIAR AQU√ç si el formato del SKU en el JSON cambia
const skuMatch = content.match(/"sku"\s*:\s*"([^"]+)"/);
```

#### 5. Si Cambia el S√≠mbolo de Moneda

**Archivo**: `scraper.js` (l√≠neas 177-185)

```javascript
// üîß CAMBIAR AQU√ç si cambian de s√≠mbolo de moneda
if (priceText.includes('‚Ç°')) {
  currency = 'CRC';
} // Agrega nuevos s√≠mbolos aqu√≠
```

### Herramientas para Debugging

```bash
# Ver la estructura del sitemap actual
curl https://www.unimart.com/sitemap.xml | head -100

# Ver el HTML de una p√°gina de producto
curl https://www.unimart.com/products/[nombre-producto] | grep -i "price\|money"

# Probar el scraper manualmente
npm run scrape
```

## Troubleshooting

### Database not loading in browser
- Make sure you have run the scraper at least once
- Verify `prices.db` exists in the repository
- Check browser console for errors

### Scraper not finding products
- The product URL patterns may need adjustment
- Check if unimart.com's sitemap structure has changed
- Modify the URL filter logic in `scraper.js`

### Price extraction issues
- Product page HTML selectors may need updating
- Check the actual HTML structure of unimart.com product pages
- Adjust the selectors in the `scrapeProduct()` function

## License

MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
